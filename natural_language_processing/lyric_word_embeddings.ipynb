{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from preprocessing import get_path, prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"variable.env\")\n",
    "artists_env = os.getenv(\"art_col\")\n",
    "lyrics_env = os.getenv(\"lyr_col\")\n",
    "titles_env = os.getenv(\"tit_col\")\n",
    "\n",
    "df = pd.read_csv(filepath_or_buffer = get_path(f\"{os.getenv('dataset')}.csv\"))\n",
    "df = df[df[os.getenv(\"lan_col\")] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyr_we = prep(df, {\"!\", \"?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[lyric_doc(words=['i', 'shot', 'the', 'sheriff', 'but', 'i', 'did', 'not', 'shoot', 'no', 'deputy', 'oh', 'no', 'oh', 'i', 'shot', 'the', 'sheriff', 'but', 'i', 'did', 'not', 'shoot', 'no', 'deputy', 'ooh', 'ooh', 'ooh', 'yeah', 'all', 'around', 'in', 'my', 'hometown', 'they', 'trying', 'to', 'track', 'me', 'down', 'yeah', 'they', 'say', 'they', 'want', 'to', 'bring', 'me', 'in', 'guilty', 'for', 'the', 'killing', 'of', 'a', 'deputy', 'for', 'the', 'life', 'of', 'a', 'deputy', 'but', 'i', 'say', 'oh', 'now', 'now', 'oh', 'i', 'shot', 'the', 'sheriff', 'the', 'sheriff', '),', 'but', 'i', 'swear', 'it', 'was', 'in', 'self', 'defense', 'no', 'no', 'ooh', 'ooh', 'ooh', 'yeah', 'i', 'said', 'i', 'shot', 'the', 'sheriff', 'oh', 'lord', 'and', 'they', 'say', 'it', 'is', 'a', 'capital', 'offense', 'oh', 'now', 'yeah', 'ooh', 'ooh', 'ooh', 'yeah', 'hear', 'this', 'sheriff', 'john', 'brown', 'always', 'hated', 'me', 'for', 'what', '?', 'i', 'do', 'not', 'know', 'every', 'time', 'i', 'plant', 'a', 'seed', 'he', 'said', 'kill', 'it', 'before', 'it', 'grows', 'he', 'said', 'kill', 'them', 'before', 'they', 'grow', 'and', 'so', 'and', 'so', 'read', 'it', 'in', 'the', 'news', 'i', 'shot', 'the', 'sheriff', 'oh', 'lord', '),', 'but', 'i', 'swear', 'it', 'was', 'in', 'self', 'defense', 'where', 'was', 'the', 'deputy', '?', 'ooh', 'ooh', 'ooh', 'i', 'said', 'i', 'shot', 'the', 'sheriff', 'but', 'i', 'swear', 'it', 'was', 'in', 'self', 'defense', 'yeah', 'ooh', 'freedom', 'came', 'my', 'way', 'one', 'day', 'and', 'i', 'started', 'out', 'of', 'town', 'yeah', 'all', 'of', 'a', 'sudden', 'i', 'saw', 'sheriff', 'john', 'brown', 'aiming', 'to', 'shoot', 'me', 'down', 'so', 'i', 'shot', 'i', 'shot', 'i', 'shot', 'him', 'down', 'and', 'i', 'say', 'if', 'i', 'am', 'guilty', 'i', 'will', 'pay', 'i', 'shot', 'the', 'sheriff', 'but', 'i', 'say', 'but', 'i', 'did', 'not', 'shoot', 'no', 'deputy', 'i', 'did', 'not', 'shoot', 'no', 'deputy', 'no', 'oh', 'no', 'oh', 'i', 'shot', 'the', 'sheriff', 'but', 'i', 'did', 'not', 'shoot', 'no', 'deputy', 'ooh', 'ooh', 'ooh', 'yeah', 'reflexes', 'had', 'the', 'better', 'of', 'me', 'and', 'what', 'is', 'to', 'be', 'must', 'be', 'every', 'day', 'the', 'bucket', 'a', 'go', 'a', 'well', 'one', 'day', 'the', 'bottom', 'a', 'go', 'drop', 'out', 'one', 'day', 'the', 'bottom', 'a', 'go', 'drop', 'out', 'i', 'say', 'i', 'i', 'i', 'i', 'shot', 'the', 'sheriff', 'lord', 'i', 'did', 'not', 'shoot', 'the', 'deputy', 'no', 'yeah', 'i', 'i', 'shot', 'the', 'sheriff', 'but', 'i', 'did', 'not', 'shoot', 'no', 'deputy', 'yeah', 'so', 'yeah'], tags=['i shot the sheriff_the wailers']),\n",
       " lyric_doc(words=['wendy', '?', 'yes', 'lisa', '?', 'is', 'the', 'water', 'warm', 'enough', '?', 'yes', 'lisa', 'shall', 'we', 'begin', '?', 'yes', 'lisa', 'where', 'is', 'my', 'love', 'life', '?', 'where', 'can', 'it', 'be', '?', 'there', 'must', 'be', 'something', 'wrong', 'with', 'the', 'machinery', 'where', 'is', 'my', 'love', 'life', '?', 'tell', 'me', 'tell', 'me', 'where', 'has', 'it', 'gone', '?', 'somebody', 'please', 'please', 'tell', 'me', 'what', 'the', 'hell', 'is', 'wrong', 'until', 'i', 'find', 'the', 'righteous', 'one', 'computer', 'blue', 'until', 'i', 'find', 'the', 'righteous', 'one', 'computer', 'blue', 'oh'], tags=['computer blue_prince']),\n",
       " lyric_doc(words=['history', 'repeats', 'the', 'old', 'conceits', 'the', 'glib', 'replies', 'the', 'same', 'defeats', 'keep', 'your', 'finger', 'on', 'important', 'issues', 'with', 'crocodile', 'tears', 'and', 'a', 'pocketful', 'of', 'tissues', 'i', 'am', 'just', 'an', 'oil', 'slick', 'in', 'a', 'windup', 'world', 'with', 'a', 'nervous', 'tick', 'in', 'a', 'very', 'fashionable', 'hovel', 'i', 'hang', 'around', 'dying', 'to', 'be', 'tortured', 'you', 'will', 'never', 'be', 'alone', 'in', 'the', 'bone', 'orchard', 'this', 'battle', 'with', 'the', 'bottle', 'is', 'nothing', 'so', 'novel', 'so', 'in', 'this', 'almost', 'empty', 'gin', 'palace', 'through', 'a', 'two', 'way', 'looking', 'glass', 'you', 'see', 'your', 'alice', 'you', 'know', 'she', 'has', 'no', 'sense', 'for', 'all', 'your', 'jealousy', 'in', 'a', 'sense', 'she', 'still', 'smiles', 'very', 'sweetly', 'charged', 'with', 'insults', 'and', 'flattery', 'her', 'body', 'moves', 'with', 'malice', 'do', 'you', 'have', 'to', 'be', 'so', 'cruel', 'to', 'be', 'callous', '?', 'and', 'now', 'you', 'find', 'you', 'fit', 'this', 'identikit', 'completely', 'you', 'say', 'you', 'have', 'no', 'secrets', 'then', 'leave', 'discreetly', 'i', 'might', 'make', 'it', 'california', 's', 'fault', 'be', 'locked', 'in', 'geneva', 's', 'deepest', 'vault', 'just', 'like', 'the', 'canals', 'of', 'mars', 'and', 'the', 'great', 'barrier', 'reef', 'i', 'come', 'to', 'you', 'beyond', 'belief', 'my', 'hands', 'were', 'clammy', 'and', 'cunning', 'she', 'is', 'been', 'suitably', 'stunning', 'but', 'i', 'know', 'there', 'is', 'not', 'a', 'hope', 'in', 'hades', 'all', 'the', 'laddies', 'cat', 'call', 'and', 'wolf', 'whistle', 'so', 'called', 'gentlemen', 'and', 'ladies', 'dog', 'fight', 'like', 'rose', 'and', 'thistle', 'i', 'have', 'got', 'a', 'feeling', 'i', 'am', 'going', 'to', 'get', 'a', 'lot', 'of', 'grief', 'once', 'this', 'seemed', 'so', 'appealing', 'now', 'i', 'am', 'beyond', 'belief', 'i', 'have', 'got', 'a', 'feeling', 'i', 'am', 'going', 'to', 'get', 'a', 'lot', 'of', 'grief', 'once', 'this', 'seemed', 'so', 'appealing', 'now', 'i', 'am', 'beyond', 'belief', 'i', 'have', 'got', 'a', 'feeling', 'i', 'am', 'going', 'to', 'get', 'a', 'lot', 'of', 'grief', 'once', 'this', 'seemed', 'so', 'appealing', 'now', 'i', 'am', 'beyond', 'belief', 'i', 'have', 'got', 'a', 'feeling'], tags=['beyond belief_elvis costello & the attractions']),\n",
       " lyric_doc(words=['i', 'will', 'love', 'you', 'anyway', 'even', 'if', 'you', 'cannot', 'stay', 'i', 'think', 'you', 'are', 'the', 'one', 'for', 'me', 'here', 'is', 'where', 'you', 'ought', 'to', 'be', 'i', 'just', 'want', 'to', 'satisfy', 'ya', 'you', 'are', 'not', 'mine', 'and', 'i', 'cannot', 'deny', 'it', 'do', 'not', 'you', 'hear', 'me', 'talking', 'baby', 'love', 'me', 'now', 'or', 'i', 'will', 'go', 'crazy', 'woah', 'oh', 'sweet', 'thing', 'oh', 'you', 'know', 'you', 'are', 'my', 'everything', 'woah', 'oh', 'sweet', 'thing', 'oh', 'you', 'know', 'you', 'are', 'my', 'everything', 'yes', 'you', 'are', 'i', 'wish', 'you', 'were', 'my', 'lover', 'but', 'you', 'act', 'so', 'undercover', 'to', 'love', 'you', 'child', 'my', 'whole', 'life', 'long', 'be', 'it', 'right', 'or', 'be', 'it', 'wrong', 'i', 'am', 'only', 'what', 'you', 'make', 'me', 'baby', 'do', 'not', 'walk', 'away', 'do', 'not', 'be', 'so', 'shady', 'do', 'not', 'want', 'your', 'mind', 'do', 'not', 'want', 'your', 'money', 'these', 'words', 'i', 'say', 'they', 'may', 'sound', 'funny', 'but', 'woah', 'oh', 'sweet', 'thing', 'oh', 'you', 'know', 'you', 'are', 'my', 'everything', 'woah', 'oh', 'sweet', 'thing', 'oh', 'you', 'know', 'you', 'are', 'my', 'everything', 'yes', 'you', 'are', 'yes', 'you', 'are', 'you', 'are', 'my', 'heat', 'you', 'are', 'my', 'fire', 'you', 'make', 'me', 'weak', 'with', 'strong', 'desire', 'to', 'love', 'you', 'child', 'my', 'whole', 'life', 'long', 'be', 'it', 'right', 'or', 'be', 'it', 'wrong', 'i', 'just', 'want', 'to', 'satisfy', 'you', 'though', 'you', 'are', 'not', 'mine', 'i', 'cannot', 'deny', 'it', 'do', 'not', 'you', 'hear', 'me', 'talking', 'baby', 'love', 'me', 'now', 'or', 'i', 'will', 'go', 'crazy', 'you', 'are', 'the', 'heat', 'you', 'are', 'my', 'fire', 'you', 'are', 'not', 'mine', 'i', 'cannot', 'deny', 'it', 'do', 'not', 'you', 'hear', 'me', 'talking', 'baby', 'love', 'me', 'now', 'or', 'i', 'will', 'go', 'crazy', 'you', 'are', 'the', 'heat', 'you', 'are', 'my', 'fire', 'you', 'are', 'not', 'mine', 'i', 'cannot', 'deny', 'it', 'do', 'not', 'you', 'hear', 'me', 'talking', 'baby', 'love', 'me', 'now', 'or', 'i', 'will', 'go', 'crazy', 'you', 'are', 'the', 'heat', 'you', 'are', 'my', 'fire', 'you', 'are', 'not', 'mine', 'i', 'cannot', 'deny', 'it', 'do', 'not', 'you', 'hear', 'me', 'talking', 'baby', 'love', 'me', 'now', 'or', 'i', 'will', 'go', 'crazy', 'you', 'are', 'the', 'heat', 'you', 'are', 'my', 'fire', 'you', 'are', 'not', 'mine', 'i', 'cannot', 'deny', 'it', 'do', 'not', 'you', 'hear', 'me', 'talking', '...'], tags=['sweet thing_rufus & chaka khan,chaka khan']),\n",
       " lyric_doc(words=['oh', 'my', 'baby', 'baby', 'i', 'love', 'you', 'more', 'than', 'i', 'can', 'tell', 'i', 'do', 'not', 'think', 'i', 'can', 'live', 'without', 'you', 'and', 'i', 'know', 'that', 'i', 'never', 'will', 'oh', 'my', 'baby', 'baby', 'i', 'want', 'you', 'so', 'it', 'scares', 'me', 'to', 'death', 'i', 'cannot', 'say', 'anymore', 'than', 'i', 'love', 'you', 'everything', 'else', 'is', 'a', 'waste', 'of', 'breath', 'i', 'want', 'you', 'you', 'have', 'had', 'your', 'fun', 'you', 'do', 'not', 'get', 'well', 'no', 'more', 'i', 'want', 'you', 'your', 'fingernails', 'go', 'dragging', 'down', 'the', 'wall', 'be', 'careful', 'darling', 'you', 'might', 'fall', 'i', 'want', 'you', 'i', 'woke', 'up', 'and', 'one', 'of', 'us', 'was', 'crying', 'i', 'want', 'you', 'you', 'said', 'young', 'man', 'i', 'do', 'believe', 'you', 'are', 'dying', 'i', 'want', 'you', 'if', 'you', 'need', 'a', 'second', 'opinion', 'as', 'you', 'seem', 'to', 'do', 'these', 'days', 'i', 'want', 'you', 'you', 'can', 'look', 'in', 'my', 'eyes', 'and', 'you', 'can', 'count', 'the', 'ways', 'i', 'want', 'you', 'did', 'you', 'mean', 'to', 'tell', 'me', 'but', 'seem', 'to', 'forget', 'i', 'want', 'you', 'since', 'when', 'were', 'you', 'so', 'generous', 'and', 'inarticulate', 'i', 'want', 'you', 'it', 'is', 'the', 'stupid', 'details', 'that', 'my', 'heart', 'is', 'breaking', 'for', 'it', 'is', 'the', 'way', 'your', 'shoulders', 'shake', 'and', 'what', 'they', 'are', 'shaking', 'for', 'i', 'want', 'you', 'it', 'is', 'knowing', 'that', 'he', 'knows', 'you', 'now', 'after', 'only', 'guessing', 'it', 'is', 'the', 'thought', 'of', 'him', 'undressing', 'you', 'or', 'you', 'undressing', 'i', 'want', 'you', 'he', 'tossed', 'some', 'tatty', 'compliment', 'your', 'way', 'i', 'want', 'you', 'and', 'you', 'were', 'fool', 'enough', 'to', 'love', 'it', 'when', 'he', 'said', 'i', 'want', 'you', 'i', 'want', 'you', 'the', 'truth', 'cannot', 'hurt', 'you', 'it', 'is', 'just', 'like', 'the', 'dark', 'it', 'scares', 'you', 'witless', 'but', 'in', 'time', 'you', 'see', 'things', 'clear', 'and', 'stark', 'i', 'want', 'you', 'go', 'on', 'and', 'hurt', 'me', 'then', 'we', 'will', 'let', 'it', 'drop', 'i', 'want', 'you', 'i', 'am', 'afraid', 'i', 'will', 'not', 'know', 'where', 'to', 'stop', 'i', 'want', 'you', 'i', 'am', 'not', 'ashamed', 'to', 'say', 'i', 'cried', 'for', 'you', 'i', 'want', 'you', 'i', 'want', 'to', 'know', 'the', 'things', 'you', 'did', 'that', 'we', 'do', 'too', 'i', 'want', 'you', 'i', 'want', 'to', 'hear', 'he', 'pleases', 'you', 'more', 'than', 'i', 'do', 'i', 'want', 'you', 'i', 'might', 'as', 'well', 'be', 'useless', 'for', 'all', 'it', 'means', 'to', 'you', 'i', 'want', 'you', 'did', 'you', 'call', 'his', 'name', 'out', 'as', 'he', 'held', 'you', 'down', 'i', 'want', 'you', 'oh', 'no', 'my', 'darling', 'not', 'with', 'that', 'clown', 'i', 'want', 'you', 'i', 'want', 'you', 'you', 'have', 'had', 'your', 'fun', 'you', 'do', 'not', 'get', 'well', 'no', 'more', 'i', 'want', 'you', 'none', 'who', 'wants', 'you', 'could', 'want', 'you', 'more', 'i', 'want', 'you', 'i', 'want', 'you', 'i', 'want', 'you', 'every', 'night', 'when', 'i', 'go', 'off', 'to', 'bed', 'and', 'when', 'i', 'wake', 'up', 'i', 'want', 'you', 'i', 'am', 'going', 'to', 'say', 'it', 'once', 'again', 'until', 'i', 'instill', 'it', 'i', 'know', 'i', 'am', 'going', 'to', 'feel', 'this', 'way', 'until', 'you', 'kill', 'it', 'i', 'want', 'you', 'i', 'want', 'you', 'i', 'want', 'you'], tags=['i want you_elvis costello & the attractions'])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyr_we.lwe_corpus(lyrics_env, [titles_env, artists_env])\n",
    "print(math.ceil(math.sqrt(lyr_we.vocabular)))\n",
    "lyr_we.lwe_train_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.191647504182561\n"
     ]
    }
   ],
   "source": [
    "lyr_we.words_per_sentence(lyrics_env)\n",
    "print(lyr_we.average_words_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_model = Doc2Vec(dm = 1,\n",
    "                      vector_size = 168, \n",
    "                      window = math.ceil(lyr_we.average_words_per_sentence),\n",
    "                      seed = 42,\n",
    "                      min_count = 2, \n",
    "                      dm_mean = 1,\n",
    "                      epochs = 10)\n",
    "lyric_model.build_vocab(lyr_we.lwe_train_corpus)\n",
    "lyric_model.train(lyr_we.lwe_train_corpus, \n",
    "                  total_examples = lyric_model.corpus_count, \n",
    "                  epochs = lyric_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, artists = zip(*(item.split(\"_\") for item in lyric_model.dv.index_to_key))\n",
    "df_lyr_we = pd.DataFrame({\n",
    "    titles_env: name,\n",
    "    artists_env: artists,\n",
    "    **{f\"lyr_we_{i}\": list(we) for i, we in enumerate(lyric_model.dv.vectors.T, start = 1)}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyr_we.to_csv(f\"{get_path('')}/lyr_we.csv\",\n",
    "                 index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
